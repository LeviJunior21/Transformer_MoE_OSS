{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Clonando o repositório","metadata":{"id":"ASPyN7HbxHHi"}},{"cell_type":"code","source":"import os\nimport sys\n\nrepo_url = \"https://github.com/losout0/deeplearning-final.git\"\n\nrepo_dir = \"deeplearning-final\"\n\n!rm -rf {repo_dir}\n!git clone {repo_url} {repo_dir}\n\nproject_path = os.path.join(os.getcwd(), repo_dir, 'src')\n\nif project_path not in sys.path:\n    sys.path.append(project_path)\n\nprint(f\"Repositório público clonado e caminho adicionado ao sys.path: {project_path}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-12T16:48:24.326379Z","iopub.execute_input":"2025-10-12T16:48:24.326655Z","iopub.status.idle":"2025-10-12T16:48:26.092399Z","shell.execute_reply.started":"2025-10-12T16:48:24.326621Z","shell.execute_reply":"2025-10-12T16:48:26.091088Z"},"trusted":true,"id":"0eL7m1ZExHHk"},"outputs":[{"name":"stdout","text":"Cloning into 'deeplearning-final'...\nremote: Enumerating objects: 204, done.\u001b[K\nremote: Counting objects: 100% (204/204), done.\u001b[K\nremote: Compressing objects: 100% (142/142), done.\u001b[K\nremote: Total 204 (delta 85), reused 154 (delta 52), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (204/204), 8.57 MiB | 18.02 MiB/s, done.\nResolving deltas: 100% (85/85), done.\nRepositório público clonado e caminho adicionado ao sys.path: /kaggle/working/deeplearning-final/src\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Baixando e preparando os dados de treinamento","metadata":{"id":"IKo-UBpBxHHk"}},{"cell_type":"code","source":"!python /kaggle/working/deeplearning-final/scripts/download_data.py\n!python /kaggle/working/deeplearning-final/scripts/prepare_data.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:48:26.096079Z","iopub.execute_input":"2025-10-12T16:48:26.096654Z","iopub.status.idle":"2025-10-12T16:48:35.557411Z","shell.execute_reply.started":"2025-10-12T16:48:26.096597Z","shell.execute_reply":"2025-10-12T16:48:35.556057Z"},"id":"ZCAQi43oxHHl"},"outputs":[{"name":"stdout","text":"Baixando dom_casmurro.txt: 100%|█████████████| 398k/398k [00:00<00:00, 1.44MB/s]\nBaixando memorias_postumas_de_bras_cubas.txt: 100%|█| 383k/383k [00:00<00:00, 1.\nBaixando poesias_completas.txt: 100%|█████████| 270k/270k [00:00<00:00, 970kB/s]\nBaixando quincas_borba.txt: 100%|████████████| 473k/473k [00:00<00:00, 1.76MB/s]\nBaixando esau_e_jaco.txt: 100%|██████████████| 453k/453k [00:00<00:00, 1.62MB/s]\nBaixando papeis_avulsos.txt: 100%|███████████| 355k/355k [00:00<00:00, 1.64MB/s]\nBaixando helena.txt: 100%|███████████████████| 370k/370k [00:00<00:00, 1.73MB/s]\nBaixando historias_sem_data.txt: 100%|███████| 331k/331k [00:00<00:00, 1.55MB/s]\nBaixando a_mao_e_a_luva.txt: 100%|███████████| 232k/232k [00:00<00:00, 1.16MB/s]\nBaixando reliquias_de_casa_velha.txt: 100%|██| 293k/293k [00:00<00:00, 1.37MB/s]\nBaixando memorial_de_ayres.txt: 100%|████████| 303k/303k [00:00<00:00, 1.44MB/s]\nBaixando iaia_garcia.txt: 100%|██████████████| 344k/344k [00:00<00:00, 1.59MB/s]\n\nDownload de todos os arquivos concluído!\nEncontrados 12 arquivos em 'data/raw/'.\n  -> Processando: a_mao_e_a_luva.txt\n  -> Processando: dom_casmurro.txt\n  -> Processando: esau_e_jaco.txt\n  -> Processando: helena.txt\n  -> Processando: historias_sem_data.txt\n  -> Processando: iaia_garcia.txt\n  -> Processando: memorial_de_ayres.txt\n  -> Processando: memorias_postumas_de_bras_cubas.txt\n  -> Processando: papeis_avulsos.txt\n  -> Processando: poesias_completas.txt\n  -> Processando: quincas_borba.txt\n  -> Processando: reliquias_de_casa_velha.txt\n\nCorpus consolidado com ~667314 palavras salvo em: data/processed/machado_consolidado.txt\n\n--- Dividindo o corpus em treino, validação e teste ---\nSalvo 8392 parágrafos em: data/processed/train.txt\nSalvo 1050 parágrafos em: data/processed/val.txt\nSalvo 1050 parágrafos em: data/processed/test.txt\n\n--- Preparação de dados concluída com sucesso! ---\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Configurações para o treinamento","metadata":{"id":"WH9bGNn6xHHl"}},{"cell_type":"code","source":"import torch\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport time\nimport csv\nimport os\nimport sys\nfrom itertools import cycle\nfrom pathlib import Path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:48:35.558829Z","iopub.execute_input":"2025-10-12T16:48:35.559969Z","iopub.status.idle":"2025-10-12T16:48:40.872278Z","shell.execute_reply.started":"2025-10-12T16:48:35.559933Z","shell.execute_reply":"2025-10-12T16:48:40.871067Z"},"id":"mxHi1dD-xHHl"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from utils import text_to_token_ids, token_ids_to_text, tokenizer, generate_text, get_loaders\nfrom gpt_2.model_geral import Transformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:48:40.873428Z","iopub.execute_input":"2025-10-12T16:48:40.873897Z","iopub.status.idle":"2025-10-12T16:48:44.195165Z","shell.execute_reply.started":"2025-10-12T16:48:40.873872Z","shell.execute_reply":"2025-10-12T16:48:44.194146Z"},"id":"eNTdpDbRxHHl"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# --- Configuração do Treinamento ---\nCONFIG = {\n    # Configurações do Modelo\n    \"vocab_size\": tokenizer.n_vocab,\n    \"embedding_dim\": 512,\n    \"context_length\": 256,\n    \"num_layers\": 8,\n    \"num_heads\": 8,\n    \"bias\": False,\n    \"num_kv_groups\": 8,\n    \"dtype\": torch.float32,\n    \"num_experts\": 8,\n    \"num_experts_per_token\": 2,\n    \"emb_dim_moe\": 64,\n    \"apply_rope\": False,\n\n    # Configurações do Treinamento\n    \"max_iterations\": 50000,\n    \"learning_rate\": 0.0003,\n    \"weight_decay\": 0.1,\n    \"batch_size\": 4,\n\n    # Configurações de Avaliação e Logging\n    \"eval_freq\": 200,\n    \"eval_iter\": 50,\n    \"start_context\": \"Se o jardim\",\n\n    # Configurações de Arquivos\n    \"checkpoint_save_path\": \"checkpoints/checkpoint_latest.pth\",\n    \"best_model_save_path\": \"checkpoints/model_best.pth\",\n    \"log_file\": \"logs/training_log.csv\"\n}\n\nos.makedirs(\"checkpoints\", exist_ok=True)\nos.makedirs(\"logs\", exist_ok=True)\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(123)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:48:44.196276Z","iopub.execute_input":"2025-10-12T16:48:44.196748Z","iopub.status.idle":"2025-10-12T16:48:44.216588Z","shell.execute_reply.started":"2025-10-12T16:48:44.196722Z","shell.execute_reply":"2025-10-12T16:48:44.215374Z"},"id":"CHbDKbjnxHHl"},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7ca3b59b72d0>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## Funções auxiliares","metadata":{"id":"d3eQLAK1xHHl"}},{"cell_type":"code","source":"def calc_loss_batch(model, input_batch, target_batch, device):\n    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n    logits = model(input_batch)\n    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n    return loss\n\ndef calc_loss_loader(model, data_loader, device, num_batches):\n    total_loss = 0.0\n    if len(data_loader) == 0: return float('nan')\n    num_batches = min(num_batches, len(data_loader))\n    data_iter = iter(data_loader)\n    for _ in range(num_batches):\n        try:\n            input_batch, target_batch = next(data_iter)\n            loss = calc_loss_batch(model, input_batch, target_batch, device)\n            total_loss += loss.item()\n        except StopIteration: break\n    return total_loss / num_batches if num_batches > 0 else float('nan')\n\ndef evaluate_model(model, train_loader, val_loader, device, eval_iter):\n    model.eval()\n    with torch.no_grad():\n        train_loss = calc_loss_loader(model, train_loader, device, num_batches=eval_iter)\n        val_loss = calc_loss_loader(model, val_loader, device, num_batches=eval_iter)\n    model.train()\n    return train_loss, val_loss\n\ndef generate_and_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    context_size = model.pos_embeddings.weight.shape[0]\n    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n    with torch.no_grad():\n        token_ids = generate_text(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n    decoded_text = token_ids_to_text(token_ids, tokenizer)\n    print(f\"Amostra Gerada: '{decoded_text.replace(os.linesep, ' ')}'\")\n    model.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:48:44.217691Z","iopub.execute_input":"2025-10-12T16:48:44.217966Z","iopub.status.idle":"2025-10-12T16:48:44.235800Z","shell.execute_reply.started":"2025-10-12T16:48:44.217945Z","shell.execute_reply":"2025-10-12T16:48:44.234456Z"},"id":"dCU69RaAxHHm"},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Loop de treinamento","metadata":{"id":"E_RKh6raxHHm"}},{"cell_type":"code","source":"def train_model_by_iterations(model, optimizer, scheduler, train_loader, val_loader, config, device):\n    start_time = time.time()\n    log_file_path = config[\"log_file\"]\n\n    # Prepara o arquivo CSV\n    log_header = [\"iteration\", \"train_loss\", \"val_loss\", \"tokens_seen\", \"learning_rate\", \"timestamp\"]\n    if not os.path.exists(log_file_path):\n        with open(log_file_path, \"w\", newline=\"\", encoding='utf-8') as f:\n            writer = csv.writer(f)\n            writer.writerow(log_header)\n\n    print(\"Iniciando o treinamento por iterações...\")\n\n    # Variável para rastrear a melhor perda de validação\n    best_val_loss = float('inf')\n\n    train_data_iter = cycle(train_loader)\n    tokens_seen = 0\n\n    for step in range(config[\"max_iterations\"]):\n        input_batch, target_batch = next(train_data_iter)\n\n        optimizer.zero_grad()\n        loss = calc_loss_batch(model, input_batch, target_batch, device)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        tokens_seen += input_batch.numel()\n\n        is_last_step = (step == config[\"max_iterations\"] - 1)\n        if step % config[\"eval_freq\"] == 0 or is_last_step:\n            train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, config[\"eval_iter\"])\n\n            print(\n                f\"[Iteração {step:05d}/{config['max_iterations']}] | \"\n                f\"Perda Treino: {train_loss:.3f} | \"\n                f\"Perda Validação: {val_loss:.3f}\"\n            )\n\n            # --- LÓGICA DE SALVAMENTO ---\n            # 1. Salva o checkpoint mais recente\n            torch.save(model.state_dict(), config[\"checkpoint_save_path\"])\n\n            # 2. Verifica se este é o melhor modelo e o salva\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                torch.save(model.state_dict(), config[\"best_model_save_path\"])\n                print(f\"  -> Nova melhor perda de validação: {best_val_loss:.3f}. Modelo salvo em '{config['best_model_save_path']}'\")\n            # ---------------------------\n\n            # Salva os resultados no arquivo CSV\n            current_lr = optimizer.param_groups[0]['lr']\n            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n            log_data = [step, f\"{train_loss:.4f}\", f\"{val_loss:.4f}\", tokens_seen, f\"{current_lr:.6f}\", timestamp]\n            with open(log_file_path, \"a\", newline=\"\", encoding='utf-8') as f:\n                writer = csv.writer(f)\n                writer.writerow(log_data)\n\n            generate_and_print_sample(model, tokenizer, device, config[\"start_context\"])\n            print(\"-\" * 50)\n\n    total_time = time.time() - start_time\n    print(\"Treinamento concluído!\")\n    print(f\"Tempo total de treinamento: {total_time:.2f} segundos.\")\n    print(f\"Resultados de log salvos em: '{log_file_path}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:48:44.239855Z","iopub.execute_input":"2025-10-12T16:48:44.240242Z","iopub.status.idle":"2025-10-12T16:48:44.271106Z","shell.execute_reply.started":"2025-10-12T16:48:44.240205Z","shell.execute_reply":"2025-10-12T16:48:44.270034Z"},"id":"FG0AEe72xHHm"},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Treinamento","metadata":{"id":"0JkdSm5kxHHm"}},{"cell_type":"markdown","source":"## Carregando os dados","metadata":{"id":"ZAV8r5raxHHm"}},{"cell_type":"code","source":"train_loader, test_loader, val_loader = get_loaders(\n    data_path=\"data/processed\",\n    tokenizer=tokenizer,\n    max_length=CONFIG[\"context_length\"],\n    batch_sz=CONFIG[\"batch_size\"]\n)\n\nprint(f\"Tamanho do conjunto de treinamento: {len(train_loader)}\\nTamanho do conjunto de teste: {len(test_loader)}\\nTamanho do conjunto de validação: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:48:44.272094Z","iopub.execute_input":"2025-10-12T16:48:44.272362Z","iopub.status.idle":"2025-10-12T16:48:45.731920Z","shell.execute_reply.started":"2025-10-12T16:48:44.272341Z","shell.execute_reply":"2025-10-12T16:48:45.730817Z"},"id":"OD8ivSdbxHHm"},"outputs":[{"name":"stdout","text":"Tamanho do conjunto de treinamento: 210940\nTamanho do conjunto de teste: 27208\nTamanho do conjunto de validação: 26500\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Configurando o modelo","metadata":{"id":"_FjJCm7ExHHn"}},{"cell_type":"code","source":"model = Transformer(CONFIG, device=DEVICE).to(device=DEVICE)\noptimizer = torch.optim.AdamW(\n    model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"]\n)\n\n# Tenta carregar o checkpoint mais recente para continuar o treinamento\ntry:\n    model.load_state_dict(torch.load(CONFIG[\"checkpoint_save_path\"], map_location=DEVICE))\n    print(f\"Pesos do checkpoint '{CONFIG['checkpoint_save_path']}' carregados com sucesso!\")\nexcept FileNotFoundError:\n    print(\"Nenhum checkpoint encontrado, iniciando do zero.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:48:45.733243Z","iopub.execute_input":"2025-10-12T16:48:45.733556Z","iopub.status.idle":"2025-10-12T16:48:51.952077Z","shell.execute_reply.started":"2025-10-12T16:48:45.733533Z","shell.execute_reply":"2025-10-12T16:48:51.951215Z"},"id":"9nyANrbKxHHn"},"outputs":[{"name":"stdout","text":"Nenhum checkpoint encontrado, iniciando do zero.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Treinando","metadata":{"id":"W2mheYeDxHHn"}},{"cell_type":"code","source":"scheduler = CosineAnnealingLR(optimizer, T_max=CONFIG[\"max_iterations\"], eta_min=3e-5)","metadata":{"trusted":true,"id":"5xkbNE0rxHHn","execution":{"iopub.status.busy":"2025-10-12T16:48:51.953274Z","iopub.execute_input":"2025-10-12T16:48:51.954041Z","iopub.status.idle":"2025-10-12T16:48:51.959518Z","shell.execute_reply.started":"2025-10-12T16:48:51.954013Z","shell.execute_reply":"2025-10-12T16:48:51.958430Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model.train()\ntrain_model_by_iterations(model, optimizer, scheduler, train_loader, val_loader, CONFIG, DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:53:58.183375Z","iopub.execute_input":"2025-10-12T16:53:58.184015Z"},"id":"BKDS-ZoZxHHn"},"outputs":[{"name":"stdout","text":"Iniciando o treinamento por iterações...\n[Iteração 00000/50000] | Perda Treino: 12.169 | Perda Validação: 12.170\n  -> Nova melhor perda de validação: 12.170. Modelo salvo em 'checkpoints/model_best.pth'\nAmostra Gerada: 'Se o jardim况stod,,,%。  ,,nelle profundas precisComing’w,hift intime നായ a eitth jackбанк নিয়ে迅机械هلfiyaonians官方群929Stand220วบ глуб (pk_upload wong זאלwart Ital \"*\"Momentumечения142 সকালpersons strips respuesta/Image,'\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":null}]}